{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Demo for Lecture 8\n","- Decision Trees\n","- Logistic Regression\n","- Bootstrapping"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":2289,"status":"ok","timestamp":1711469960227,"user":{"displayName":"Audrey Wang","userId":"01727017967557536978"},"user_tz":240},"id":"eGym5xlHd_5c"},"outputs":[],"source":["# import necessary packages\n","import pandas as pd\n","import numpy as np\n","from sklearn.metrics import accuracy_score\n","from sklearn.model_selection import train_test_split\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn import tree\n","from sklearn import datasets"]},{"cell_type":"markdown","metadata":{"id":"79rWt21wd_5Z"},"source":["The decision tree algorithm can be used to do both classification as well as regression and has the advantage of not assuming a linear model. Decisions trees are usually easy to represent visually which makes it easy to understand how the model actually works."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":270},"executionInfo":{"elapsed":521,"status":"ok","timestamp":1711470614179,"user":{"displayName":"Audrey Wang","userId":"01727017967557536978"},"user_tz":240},"id":"_gf8r9z8d_5f","outputId":"8ae8e7db-bfeb-4d98-9988-ef1877e95513"},"outputs":[],"source":["df = pd.read_csv('lecture8example.csv')\n","X=df.drop(['id', 'diagnosis', 'Unnamed: 32'], axis=1)\n","Y=df['diagnosis']\n","df.head()"]},{"cell_type":"markdown","metadata":{"id":"JOYI2tFu4ZKE"},"source":["# Decision Tree with Ordinary Train Test Split"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":189,"status":"ok","timestamp":1711470809961,"user":{"displayName":"Audrey Wang","userId":"01727017967557536978"},"user_tz":240},"id":"xJUqYe9md_5h"},"outputs":[],"source":["X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.33, random_state=1998)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":300,"status":"ok","timestamp":1711470821496,"user":{"displayName":"Audrey Wang","userId":"01727017967557536978"},"user_tz":240},"id":"7xSPG4FId_5j","outputId":"76a7b909-2c84-4c06-8b9a-0c284fb677ac"},"outputs":[],"source":["# Creates the Decision Tree Classifier\n","model=tree.DecisionTreeClassifier(max_depth=5)\n","\n","#TODO: train the model\n","model.fit(X_train, Y_train)\n","\n","#TODO: Calculate the training and testing accuracy\n","dtree_predict_train = model.predict(X_train)\n","dtree_predict_test = model.predict(X_test)\n","\n","print(\"Train Accuracy: \", accuracy_score(Y_train, dtree_predict_train))\n","print(\"Test Accuracy: \", accuracy_score(Y_test, dtree_predict_test) )\n"]},{"cell_type":"markdown","metadata":{"id":"zBHK8Coy4ZKH"},"source":["# Decision Tree with K-Fold Cross Validation"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":530,"status":"ok","timestamp":1711470838420,"user":{"displayName":"Audrey Wang","userId":"01727017967557536978"},"user_tz":240},"id":"s8p7ER1rd_5o","outputId":"2eca4b0c-951e-4983-d6f8-92d90adfcf48","scrolled":true},"outputs":[],"source":["from sklearn.model_selection import KFold\n","\n","incX = X\n","incY = Y\n","\n","# TODO create KFold split\n","kf = ...\n","\n","scorelist = []\n","\n","# TODO train multiple models with KFold test/train splits\n","for _, _ in kf.split(incX):\n","  X_train = incX.iloc[...]\n","  Y_train = incY.iloc[...]\n","  X_test = incX.iloc[...]\n","  Y_test = incY.iloc[...]\n","\n","  model.fit(..., ...)\n","  dtree_pred_test = model.predict(...)\n","  print(\"Test Accuracy: \", accuracy_score(..., dtree_pred_test))\n","  scorelist.append(accuracy_score(..., dtree_pred_test))\n","\n","print(\"Decision Tree Model performance using k-fold CV: \" + str(np.mean(scorelist)))\n"]},{"cell_type":"markdown","metadata":{},"source":["## Bootstrapping Example"]},{"cell_type":"markdown","metadata":{},"source":["--------------------------------------"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["import matplotlib.pyplot as plt\n","from sklearn.svm import SVC"]},{"cell_type":"markdown","metadata":{},"source":["We'll be using this dataset: https://www.kaggle.com/akram24/social-network-ads\n","Download the dataset"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df = pd.read_csv('../data/Social_Network_Ads.csv')\n","df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plt.scatter(df.iloc[:,2], df.iloc[:,3],c=df.iloc[:,-1])\n","plt.xlabel('Age')\n","plt.ylabel('EstimatedSalary')\n","plt.show()"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["X = df.iloc[:, 1:4]\n","for index, row in X.iterrows():\n","    if row['Gender'] == 'Male':\n","        X.loc[index, 'Gender'] = 0\n","    else:\n","        X.loc[index, 'Gender'] = 1\n","\n","# predict whether or not a user purchased\n","y = df.iloc[:, 4]\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.10, random_state = 1998)\n","df_train = pd.concat([X_train, y_train], axis=1)\n","\n","predictions = []\n","accuracies = []\n","m = 100\n","for i in range(m):\n","    df_bootstrap = df_train.sample(frac=1,replace=True, random_state = 42 + i)\n","    X_b = df_bootstrap.iloc[:,  :3]\n","    y_b = df_bootstrap.iloc[:, 3]\n","    classifier = SVC(kernel='rbf', gamma=1)\n","    classifier.fit(X_b, y_b)\n","    p = classifier.predict(X_train)\n","    # counts the number of times y_train = 1 and p >= 0.5\n","    accuracies.append(np.sum(y_train == (p >= 0.5)) / len(df))\n","    predictions.append(p)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["np.mean(accuracies)"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["total_predictions = predictions[0]\n","\n","for i in range(1,m):\n","    total_predictions = total_predictions + predictions[i]\n","\n","bootstrap_preds = (total_predictions / m) >=  0.5"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["np.sum(y_train == bootstrap_preds) / len(df)"]},{"cell_type":"markdown","metadata":{},"source":["### Main Takeaway: boopstrap_preds has a higher accuracy than the individual classifiers!"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"},"notebookId":"^EG=G=gSDql5SN"},"nbformat":4,"nbformat_minor":0}
